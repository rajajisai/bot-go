mcp:
  host: "localhost"
  port: 8282
app:
  port: 8181
  codegraph: false
  gopls: "${BOT_GO_PATH}/scripts/gopls.sh"
  python: "${BOT_GO_PATH}/scripts/pylsp.sh"
  num_file_threads: 2
neo4j:
  uri: "bolt://localhost:7687"
  username: "neo4j"
  password: "neo4j"
kuzu:
  path: "data/kuzu.db"
qdrant:
  host: "localhost"
  port: 6334  # gRPC port (6333 is HTTP/REST)
  apikey: ""
ollama:
  url: "http://localhost:11434"
  apikey: ""
  model: "qwen3-embedding:0.6b"  # qwen3-embedding:0.6b produces 1024 dimensions
  # model: "nomic-embed-text"  # Options: nomic-embed-text (768d), all-minilm (384d), mxbai-embed-large (1024d)
  dimension: 1024  # Must match the model's output dimension
chunking:
  # Minimum number of lines for conditionals/loops to be stored as separate chunks
  # Small conditionals/loops will be included in their parent function but not stored separately
  min_conditional_lines: 8
  min_loop_lines: 8
index_building:
  # Configuration for build-index CLI mode
  # Controls which processing steps are enabled when building indexes
  enable_code_graph: true      # Build code graph using tree-sitter and LSP
  enable_embeddings: true      # Generate and store code embeddings in vector DB
  enable_ngram: true           # Build n-gram model for code analysis
